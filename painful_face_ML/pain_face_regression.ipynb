{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.image as mp_image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_filename(full_name, filename_extension):\n",
    "    return full_name.split(sep=\".\"+filename_extension)[0].split(sep='/')[-1]\n",
    "\n",
    "extract_png_filename = partial(extract_filename, filename_extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取訓練資料到陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ground truth\n",
    "df_UNBC_pain_score = pd.read_csv('./UNBC_pain_score_table.csv') # 讀取疼痛分數資料\n",
    "df_UNBC_pain_score.sort_values(by=['PSPI'], ascending=False, inplace=True) # 高分排前面\n",
    "df_UNBC_pain_score.reset_index(drop=True, inplace=True) # 更新 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 46376\n"
     ]
    }
   ],
   "source": [
    "# feed training data\n",
    "\n",
    "# 建構檔案路徑\n",
    "# croped_face_folder = '../datalake/crop_face_from_UNBC_pain/'\n",
    "file_ext = '.png'\n",
    "# 讀取目錄底下所有檔案絕對路徑\n",
    "paths_croped_face_img = subprocess.getoutput('find /home/lky/crop_face_from_UNBC_pain_GCP/ -type f -name \"*.png\"').split('\\n')\n",
    "print(\"count = {}\".format(+len(paths_croped_face_img)))\n",
    "# paths_croped_face_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 只使用有被偵測到臉的\n",
    "df_croped_face_img = pd.DataFrame(\n",
    "                        data = {'full_name':paths_croped_face_img, \n",
    "                                'file_name':[i for i in map(extract_png_filename, paths_croped_face_img)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46376\n"
     ]
    }
   ],
   "source": [
    "# 合併檔案路徑表和分數表，之後只用這張表，清空不必要變數\n",
    "df_croped_face_img = df_croped_face_img.merge(right=df_UNBC_pain_score, on='file_name', how='inner')\n",
    "paths_croped_face_img = []\n",
    "df_UNBC_pain_score = []\n",
    "print(df_croped_face_img.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 把臉部 ROI 轉化成可以直接輸入 nn 的 vector\n",
    "def rect_img_to_input_vector(raw_img):\n",
    "    import skimage\n",
    "    gray_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2GRAY) #轉灰\n",
    "#     gray_img = cv2.equalizeHist(gray_img) #亮度正規化\n",
    "    norm_size_img = cv2.resize(gray_img,(128, 128)) #統一尺寸\n",
    "    max_pooling_img = skimage.measure.block_reduce(norm_size_img, (2,2), np.max) #最大池化\n",
    "    reshape_img = np.reshape(max_pooling_img, [-1]) #拉平\n",
    "    return reshape_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 讀取影像函式\n",
    "def read_dataset(list_data_path):\n",
    "    import skimage.measure\n",
    "    dataset = []\n",
    "    read_fail_set = []\n",
    "    print(\"read img {:5d}, {}\".format(len(dataset), subprocess.getoutput('date')))\n",
    "    #-------------------------------------------------------------------\n",
    "    for img_full_name in list_data_path:\n",
    "        try:\n",
    "            raw_img = cv2.imread(img_full_name)\n",
    "        except:\n",
    "            read_fail_set.append(img_full_name)\n",
    "            print(img_full_name, len(read_fail_set))\n",
    "\n",
    "        dataset.append(rect_img_to_input_vector(raw_img)) #push in list\n",
    "\n",
    "        if(0 == len(dataset)%5000):\n",
    "            print(\"read img {:5d}, {}\".format(len(dataset), subprocess.getoutput('date')))\n",
    "    #-------------------------------------------------------------------\n",
    "    print(\"read img {:5d}, {}\".format(len(dataset), subprocess.getoutput('date')))\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 分割 [ 訓練集 , 測試集 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# shuffle\n",
    "df_croped_face_img = df_croped_face_img.reindex(index = np.random.permutation(df_croped_face_img.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 只以 PSPI 排序\n",
    "df_croped_face_img.sort_values(by=['PSPI'], ascending=False, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 重新給 index，不留原本的 index\n",
    "df_croped_face_img.reset_index(inplace=True, drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 雙數抽樣(訓練集)\n",
    "df_croped_face_img_training = df_croped_face_img.iloc[[i for i in df_croped_face_img.index if i&1==0 ],:]\n",
    "\n",
    "# 單數抽樣(測試集)\n",
    "df_croped_face_img_validation = df_croped_face_img.iloc[[i for i in df_croped_face_img.index if i&1==1 ],:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取資料集影像內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read img     0, 五  9月  8 16:14:08 CST 2017\n",
      "read img  5000, 五  9月  8 16:14:22 CST 2017\n",
      "read img 10000, 五  9月  8 16:14:40 CST 2017\n",
      "read img 15000, 五  9月  8 16:14:57 CST 2017\n",
      "read img 20000, 五  9月  8 16:15:14 CST 2017\n",
      "read img 23188, 五  9月  8 16:15:23 CST 2017\n",
      "read img     0, 五  9月  8 16:15:23 CST 2017\n",
      "read img  5000, 五  9月  8 16:15:38 CST 2017\n",
      "read img 10000, 五  9月  8 16:15:52 CST 2017\n",
      "read img 15000, 五  9月  8 16:16:10 CST 2017\n",
      "read img 20000, 五  9月  8 16:16:27 CST 2017\n",
      "read img 23188, 五  9月  8 16:16:36 CST 2017\n"
     ]
    }
   ],
   "source": [
    "training_img_dataset = read_dataset(df_croped_face_img_training['full_name'])\n",
    "validation_img_dataset = read_dataset(df_croped_face_img_validation['full_name'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "五  9月  8 16:16:43 CST 2017\n"
     ]
    }
   ],
   "source": [
    "# 對資料集正規化\n",
    "## 正規化的單位並不是一張影像，而是一個位置，所以是對每一張影像的同一個位置的像素正規化\n",
    "from sklearn import preprocessing\n",
    "normalizer = preprocessing.MinMaxScaler(feature_range=(-0.9, 0.9))\n",
    "normalizer.fit( training_img_dataset + validation_img_dataset ) # 訓練驗證一起 fit 正規化模型\n",
    "training_img_dataset = normalizer.transform(training_img_dataset) # 訓練集轉換\n",
    "validation_img_dataset = normalizer.transform(validation_img_dataset) # 驗證集轉換\n",
    "print(\"{}\".format(subprocess.getoutput('date')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建構神經網路\n",
    "\n",
    "# 單層建構函式\n",
    "def make_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "in_size = 64*64\n",
    "out_size = 1 \n",
    "\n",
    "# 定義輸出入變數\n",
    "xs = tf.placeholder(tf.float32, [None, in_size])\n",
    "ys = tf.placeholder(tf.float32, [None, out_size])\n",
    "\n",
    "# 定義多層流程\n",
    "layer_hidden_1 = make_layer(xs, in_size, 64, activation_function = tf.nn.tanh)\n",
    "layer_output   = make_layer(layer_hidden_1, 64, out_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義損失函數\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - layer_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義學習方法\n",
    "learning_rate = 0.003\n",
    "momentum = 0.1\n",
    "# train_step = tf.train.MomentumOptimizer(learning_rate, momentum).minimize(loss)\n",
    "train_step = tf.train.MomentumOptimizer(learning_rate, momentum).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 變數初始化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = None, cost = 91.07775573572538, 五  9月  8 16:18:03 CST 2017\n",
      "epoch = 0, cost = 1.492387630455408, 五  9月  8 16:18:34 CST 2017\n",
      "epoch = 1, cost = 1.1962593293136536, 五  9月  8 16:19:02 CST 2017\n",
      "epoch = 2, cost = 1.1783268487471967, 五  9月  8 16:19:37 CST 2017\n",
      "epoch = 3, cost = 1.0893211871442126, 五  9月  8 16:20:14 CST 2017\n",
      "epoch = 4, cost = 1.215447679025789, 五  9月  8 16:20:47 CST 2017\n",
      "epoch = 5, cost = 0.9060680632223564, 五  9月  8 16:21:23 CST 2017\n",
      "epoch = 6, cost = 0.9370267959181473, 五  9月  8 16:21:51 CST 2017\n",
      "epoch = 7, cost = 1.0395725968173193, 五  9月  8 16:22:19 CST 2017\n",
      "epoch = 8, cost = 0.8534354380498533, 五  9月  8 16:22:50 CST 2017\n",
      "epoch = 9, cost = 0.9237418734905986, 五  9月  8 16:23:22 CST 2017\n",
      "epoch = 10, cost = 1.3375233822451267, 五  9月  8 16:23:51 CST 2017\n",
      "epoch = 11, cost = 0.8334725935828877, 五  9月  8 16:24:23 CST 2017\n",
      "epoch = 12, cost = 0.7065374938006728, 五  9月  8 16:24:54 CST 2017\n",
      "epoch = 13, cost = 0.6889851852925004, 五  9月  8 16:25:30 CST 2017\n",
      "epoch = 14, cost = 0.6831914254544377, 五  9月  8 16:26:00 CST 2017\n",
      "epoch = 15, cost = 0.7549811088979214, 五  9月  8 16:26:42 CST 2017\n",
      "epoch = 16, cost = 0.6645968550543384, 五  9月  8 16:27:21 CST 2017\n",
      "epoch = 17, cost = 0.7353294100127221, 五  9月  8 16:27:56 CST 2017\n",
      "epoch = 18, cost = 0.8750453999644212, 五  9月  8 16:28:37 CST 2017\n",
      "epoch = 19, cost = 0.5945199884503838, 五  9月  8 16:29:11 CST 2017\n"
     ]
    }
   ],
   "source": [
    "# 模型訓練前的整體誤差\n",
    "cost = sess.run(loss, feed_dict = {\n",
    "                                    xs: training_img_dataset,\n",
    "                                    ys: [[i] for i in df_croped_face_img_training['PSPI']]})\n",
    "print(\"epoch = None, cost = {}, {}\".format(cost/len(training_img_dataset) , subprocess.getoutput('date')))\n",
    "\n",
    "# 訓練\n",
    "for epoch in range(20):\n",
    "    train_squence = [i for i in range(len(training_img_dataset))] #產生線性的資料流水號序列\n",
    "    np.random.shuffle(train_squence)\n",
    "    \n",
    "    # 這一輪訓練\n",
    "    for i in train_squence:\n",
    "        _ = sess.run([train_step], feed_dict = {\n",
    "                                            xs: [training_img_dataset[i]],\n",
    "                                            ys: [[df_croped_face_img_training['PSPI'].iloc[i]]]})\n",
    "    \n",
    "    # 這一輪訓練後的整體誤差\n",
    "    cost = sess.run(loss, feed_dict = {\n",
    "                                    xs: training_img_dataset,\n",
    "                                    ys: [[i] for i in df_croped_face_img_training['PSPI']]})\n",
    "    print(\"epoch = {}, cost = {}, {}\".format(epoch, cost/len(training_img_dataset) , subprocess.getoutput('date')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCCs = [[ 1.          0.75508123]\n",
      "        [ 0.75508123  1.        ]]\n",
      "MSE  = 0.7373299312125363\n"
     ]
    }
   ],
   "source": [
    "# 計算實驗結果\n",
    "from sklearn.metrics import mean_squared_error\n",
    "predict_result = sess.run(layer_output, feed_dict={xs:validation_img_dataset})[:,0]\n",
    "ground_truth = df_croped_face_img_validation['PSPI'].values\n",
    "print(\"PCCs = {}\".format(np.corrcoef(x=ground_truth, y=predict_result)).replace('\\n','\\n'+' '*7))\n",
    "print(\"MSE  = {}\".format(mean_squared_error(ground_truth, predict_result)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_model/train_net_by_pain_face.ckpt\n"
     ]
    }
   ],
   "source": [
    "# 模型存檔\n",
    "saver = tf.train.Saver()\n",
    "saver_path = saver.save(sess, \"trained_model/train_net_by_pain_face.ckpt\")\n",
    "print(saver_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 即時推論檢驗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython import display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# len(training_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.22474487, -1.22474487, -1.22474487],\n",
       "       [ 0.        ,  0.        ,  0.        ],\n",
       "       [ 1.22474487,  1.22474487,  1.22474487]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normalizer = preprocessing.StandardScaler(\n",
    "#     with_mean=True, with_std=True\n",
    ")\n",
    "normalizer.fit_transform([[1,2,3],[4,5,6],[7,8,9]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vc = cv2.VideoCapture(0)\n",
    "\n",
    "if vc.isOpened(): # try to get the first frame\n",
    "    is_capturing, frame = vc.read()\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "    webcam_preview = plt.imshow(frame)    \n",
    "else:\n",
    "    is_capturing = False\n",
    "\n",
    "# 人臉辨識分類器初始化\n",
    "face_cascade = cv2.CascadeClassifier('../haarcascades/haarcascade_frontalface_alt2.xml')\n",
    "            \n",
    "while is_capturing:\n",
    "    try:    # Lookout for a keyboardInterrupt to stop the script\n",
    "        is_capturing, frame = vc.read()\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)    # makes the blues image look real colored\n",
    "        \n",
    "        #----------------------\n",
    "        _faces = face_cascade.detectMultiScale(frame, 1.1, 3, minSize = (96, 96))\n",
    "        # 如果有偵測到臉\n",
    "        if(() != _faces):\n",
    "            x,y,w,h = _faces[0]\n",
    "            pspi = sess.run(\n",
    "                    layer_output,\n",
    "                    feed_dict={xs:rect_img_to_input_vector(frame[y:y+h, x:x+w])})\n",
    "            print(pspi)\n",
    "            cv2.rectangle(frame,(x,y), (x+w,y+h), (0xFF,0,0), thickness =2)\n",
    "            cv2.putText(\n",
    "                img = frame,\n",
    "                text = \"PSPI={}\".format(pspi),\n",
    "                org = (20,20),\n",
    "                fontFace = cv2.FONT_HERSHEY_SIMPLEX,\n",
    "                fontScale = 2,\n",
    "                color = (255 ,0 ,0))\n",
    "        #----------------------\n",
    "        \n",
    "        webcam_preview.set_data(frame)\n",
    "        plt.draw()\n",
    "\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())\n",
    "\n",
    "        plt.pause(1/30)    # the pause time is = 1 / framerate\n",
    "    except KeyboardInterrupt:\n",
    "        vc.release()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
