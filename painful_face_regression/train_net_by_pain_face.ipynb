{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mp_image\n",
    "import matplotlib.pyplot as plt\n",
    "import subprocess\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import cv2\n",
    "from functools import partial\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_filename(full_name, filename_extension):\n",
    "    return full_name.split(sep=\".\"+filename_extension)[0].split(sep='/')[-1]\n",
    "\n",
    "extract_png_filename = partial(extract_filename, filename_extension='png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 讀取訓練資料到陣列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ground truth\n",
    "df_UNBC_pain_score = pd.read_csv('./UNBC_pain_score_table.csv') # 讀取疼痛分數資料\n",
    "df_UNBC_pain_score.sort_values(by=['PSPI'], ascending=False, inplace=True) # 高分排前面\n",
    "df_UNBC_pain_score.reset_index(drop=True, inplace=True) # 更新 index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count = 46376\n"
     ]
    }
   ],
   "source": [
    "# feed training data\n",
    "\n",
    "# 建構檔案路徑\n",
    "# croped_face_folder = '../datalake/crop_face_from_UNBC_pain/'\n",
    "file_ext = '.png'\n",
    "# 讀取目錄底下所有檔案絕對路徑\n",
    "paths_croped_face_img = subprocess.getoutput('find /home/lky/crop_face_from_UNBC_pain_GCP/ -type f -name \"*.png\"').split('\\n')\n",
    "print(\"count = {}\".format(+len(paths_croped_face_img)))\n",
    "# paths_croped_face_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 只使用有被偵測到臉的\n",
    "df_croped_face_img = pd.DataFrame(\n",
    "                        data = {'full_name':paths_croped_face_img, \n",
    "                                'file_name':[i for i in map(extract_png_filename, paths_croped_face_img)]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46376\n"
     ]
    }
   ],
   "source": [
    "# 合併檔案路徑表和分數表，之後只用這張表，清空不必要變數\n",
    "df_croped_face_img = df_croped_face_img.merge(right=df_UNBC_pain_score, on='file_name', how='inner')\n",
    "paths_croped_face_img = []\n",
    "df_UNBC_pain_score = []\n",
    "print(df_croped_face_img.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "46376\n"
     ]
    }
   ],
   "source": [
    "# 流程測試用\n",
    "# df_croped_face_img = df_croped_face_img[:1000]\n",
    "print(df_croped_face_img.index.size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "read img     0, 四  9月  7 14:03:03 CST 2017\n",
      "read img  5000, 四  9月  7 14:03:18 CST 2017\n",
      "read img 10000, 四  9月  7 14:03:33 CST 2017\n",
      "read img 15000, 四  9月  7 14:03:47 CST 2017\n",
      "read img 20000, 四  9月  7 14:04:01 CST 2017\n",
      "read img 25000, 四  9月  7 14:04:16 CST 2017\n",
      "read img 30000, 四  9月  7 14:04:29 CST 2017\n",
      "read img 35000, 四  9月  7 14:04:43 CST 2017\n",
      "read img 40000, 四  9月  7 14:04:57 CST 2017\n",
      "read img 45000, 四  9月  7 14:05:11 CST 2017\n"
     ]
    }
   ],
   "source": [
    "# tensorflow 讀取影像\n",
    "import skimage.measure\n",
    "training_dataset = []\n",
    "read_fail_set = []\n",
    "print(\"read img {:5d}, {}\".format(len(training_dataset), subprocess.getoutput('date')))\n",
    "\n",
    "#-------------------------------------------------------------------\n",
    "\n",
    "for img_full_name in df_croped_face_img['full_name']:\n",
    "    try:\n",
    "        raw_img = cv2.imread(img_full_name)\n",
    "    except:\n",
    "        read_fail_set.append(img_full_name)\n",
    "        print(img_full_name, len(read_fail_set))\n",
    "\n",
    "    gray_img = cv2.cvtColor(raw_img, cv2.COLOR_BGR2GRAY) #轉灰\n",
    "    gray_img = cv2.equalizeHist(gray_img) #亮度正規化\n",
    "    norm_size_img = cv2.resize(gray_img,(64, 64)) #統一尺寸\n",
    "    norm_size_img = skimage.measure.block_reduce(norm_size_img, (2,2), np.max) #最大池化\n",
    "    reshape_img = np.reshape(norm_size_img, [-1]) #拉平\n",
    "    training_dataset.append(reshape_img) #push in list\n",
    "    \n",
    "    if(0 == len(training_dataset)%5000):\n",
    "        print(\"read img {:5d}, {}\".format(len(training_dataset), subprocess.getoutput('date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neural Network construct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義輸出入變數\n",
    "input_layer = tf.placeholder(dtype=tf.float32, shape=[None, 1024], name='input_layer')\n",
    "ground_truth = tf.placeholder(dtype=tf.float32, shape=[None, 1], name='ground_truth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 建構神經網路\n",
    "\n",
    "# 單層建構函式\n",
    "def make_layer(inputs, in_size, out_size, activation_function=None):\n",
    "    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n",
    "    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n",
    "    Wx_plus_b = tf.add(tf.matmul(inputs, Weights), biases)\n",
    "    if activation_function is None:\n",
    "        outputs = Wx_plus_b\n",
    "    else:\n",
    "        outputs = activation_function(Wx_plus_b)\n",
    "    return outputs\n",
    "\n",
    "in_size = 1024\n",
    "out_size = 1 \n",
    "\n",
    "# 定義輸出入變數\n",
    "xs = tf.placeholder(tf.float32, [None, in_size])\n",
    "ys = tf.placeholder(tf.float32, [None, out_size])\n",
    "\n",
    "# 定義多層流程\n",
    "my_activation_function = tf.nn.tanh # 統一中間層活化函數\n",
    "layer_hidden_1 = make_layer(xs, in_size, 32, activation_function=my_activation_function)\n",
    "layer_output   = make_layer(layer_hidden_1, 32, out_size) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義損失函數\n",
    "loss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - layer_output)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 定義學習方法\n",
    "train_step = tf.train.GradientDescentOptimizer(0.003).minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 變數初始化\n",
    "init = tf.global_variables_initializer()\n",
    "sess = tf.Session()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch = 0, cost = [0.0029676273], 四  9月  7 15:14:20 CST 2017\n",
      "epoch = 1, cost = [0.28248096], 四  9月  7 15:14:44 CST 2017\n",
      "epoch = 2, cost = [0.005077899], 四  9月  7 15:15:09 CST 2017\n",
      "epoch = 3, cost = [2.3907268], 四  9月  7 15:15:33 CST 2017\n",
      "epoch = 4, cost = [0.23021726], 四  9月  7 15:15:58 CST 2017\n"
     ]
    }
   ],
   "source": [
    "# 訓練\n",
    "for epoch in range(5):\n",
    "    train_squence = np.linspace(\n",
    "                                0,len(training_dataset),len(training_dataset),\n",
    "                                dtype=int, endpoint=False)\n",
    "    np.random.shuffle(train_squence)\n",
    "    for i in train_squence:\n",
    "        _ = sess.run([train_step], feed_dict = {\n",
    "                                            xs: [training_dataset[i]],\n",
    "                                            ys: [[df_croped_face_img['PSPI'][i]]]})\n",
    "            \n",
    "    cost = sess.run([loss], feed_dict = {\n",
    "                                    xs: [training_dataset[i]],\n",
    "                                    ys: [[df_croped_face_img['PSPI'][i]]]})\n",
    "    print(\"epoch = {}, cost = {}, {}\".format(epoch, cost, subprocess.getoutput('date')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crop face to file from UNBC pain dataset.ipynb\t train_net_by_pain_face.ipynb\r\n",
      "reconstruct UNBC pain database PSPI index.ipynb  UNBC_pain_score_table.csv\r\n",
      "trained_model\r\n"
     ]
    }
   ],
   "source": [
    "! ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained_model/train_net_by_pain_face.ckpt\n"
     ]
    }
   ],
   "source": [
    "saver = tf.train.Saver()\n",
    "saver_path = saver.save(sess, \"trained_model/train_net_by_pain_face.ckpt\")\n",
    "print(saver_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
